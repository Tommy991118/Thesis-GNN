{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building prediction models using the created embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a step-by-step guide to create multiple prediction models with the created embeddings. The code can only be runned after creating the embedding by using the GLACE train.py file.\n",
    "\n",
    "The notebook consist out of three main sections.\n",
    "- The first sections combines the chosen embedding together with the raw data after which it constructs three different models: Linear regression, XGBoost regressor and Random Forest regressor. For each of the models the code to perform the gridsearch is also present. \n",
    "- The second section utilizes only the raw data features and was used to acquire the baseline results.\n",
    "- The third section contains the feature importance analysis using Shap-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, ShuffleSplit, train_test_split\n",
    "import sklearn.metrics\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm, skew \n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling for embedding + RAW"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data and drop variables that skew the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network embedding generated by GLACE\n",
    "ps = pd.read_pickle('GLACE/emb/glace_cora_ml_embedding_first-order_Final_house.pkl')\n",
    "labels = pd.read_csv(\"price_label_final.csv\")\n",
    "base_df = pd.read_csv(\"BaseKCFinal.csv\")\n",
    "base_df = base_df.drop([\"id\"], axis=1)\n",
    "base_df = base_df.drop([\"index\"], axis=1)\n",
    "base_df = base_df.drop(base_df.columns[0],axis = 1)\n",
    "base_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of the content of the network embedding for node 2.\n",
    "print(\"mu of node 2: \", ps[\"mu\"][2])\n",
    "print(100*\"*\")\n",
    "print(\"sigma of node 2: \", ps[\"sigma\"][2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run following code only if influence of latitude and longitude on results has to be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create raw set without lat and lon\n",
    "df_no_lat =  base_df.drop(['lat','long'], axis = 1)\n",
    "base_df = df_no_lat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing train-test split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run if House-House embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = round(len(labels)*0.2)\n",
    "X_train =  np.array([np.array(ps['mu'][k]) for k in range(0, len(ps['mu']) - test_size)])\n",
    "X_test = np.array([np.array(ps['mu'][k]) for k in range(len(ps['mu']) - test_size, len(ps['mu']))])\n",
    "\n",
    "y_train =  np.array([np.array(labels['price'][k]) for k in range(0, len(labels['price']) - test_size)])\n",
    "y_test = np.array([np.array(labels['price'][k]) for k in range(len(labels['price']) - test_size, len(labels['price']))])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run if House-School embedding**\n",
    "\n",
    "Different code since only the information of the houses will be used. The embedding variables already contain the information of nearby schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = len(labels) - round(len(labels)*0.2)\n",
    "X_train =  np.array([np.array(ps['mu'][k]) for k in range(0,test_split)])\n",
    "X_test = np.array([np.array(ps['mu'][k]) for k in range(test_split, len(labels))])\n",
    "\n",
    "y_train =  np.array([np.array(labels['price'][k]) for k in range(0,test_split)])\n",
    "y_test = np.array([np.array(labels['price'][k]) for k in  range(test_split, len(labels))])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert 2D numpy array into pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train.tolist(), columns=[\"col_\" + str(i) for i in range(X_train.shape[1])])\n",
    "X_test = pd.DataFrame(X_test.tolist(), columns=[\"col_\" + str(i) for i in range(X_test.shape[1])])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check dataframe shapes. Number of columns should be the same!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train shape: \", X_train.shape)\n",
    "print(\"test shape: \", X_test.shape)\n",
    "print(\"base_Df shape: \", base_df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape raw data to make sure that indices line up with their respective nodes. Adjust numbers based on the shape sizes of previous code. \n",
    "\n",
    "14270 houses are part of the train set and 3568 houses are part of the test set. House instances were ordered on their index and train-test split hasn't been performed randomly. This has been done to ensure we can add the correct raw data to the correct houses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df_train = base_df.head(14270)\n",
    "base_df_train.shape\n",
    "base_df_test = base_df.tail(3568)\n",
    "base_df_test.reset_index(drop=True, inplace=True)\n",
    "base_df_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the dataframe containing the values of the network embedding and the data from the raw dataframe. Also remove label from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_concatenated = pd.concat([X_train, base_df_train], axis=1)\n",
    "X_test_concatenated = pd.concat([X_test, base_df_test], axis=1)\n",
    "X_train_concatenated.drop([\"price\"], inplace=True, axis=1)\n",
    "X_test_concatenated.drop([\"price\"], inplace=True, axis=1)\n",
    "X_train = X_train_concatenated\n",
    "X_test = X_test_concatenated\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing & exploration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration of the target variable (price) distribution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate the distribution of the target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_train , fit=norm)\n",
    "\n",
    "# Get the fitted parameters used by the function\n",
    "(mu, sigma) = norm.fit(y_train)\n",
    "print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n",
    "\n",
    "# Now plot the distribution\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SalePrice distribution')\n",
    "\n",
    "# Get also the QQ-plot\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(y_train, plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the target variable is skewed. This could affect the performance of the prediction models\n",
    "\n",
    "Perform log-transformation on the target variable in the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use the numpy fuction log1p which  applies log(1+x) to all elements of the column\n",
    "y_train = np.log1p(y_train)\n",
    "\n",
    "#Check the new distribution \n",
    "sns.distplot(y_train , fit=norm);\n",
    "\n",
    "# Get the fitted parameters used by the function\n",
    "(mu, sigma) = norm.fit(y_train)\n",
    "print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n",
    "\n",
    "#Now plot the distribution\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SalePrice distribution')\n",
    "\n",
    "#Get also the QQ-plot\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(y_train, plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the numpy fuction log1p which applies log(1+x) to all elements of the column\n",
    "y_test = np.log1p(y_test)\n",
    "\n",
    "#Check the new distribution \n",
    "sns.distplot(y_test , fit=norm);\n",
    "\n",
    "# Get the fitted parameters used by the function\n",
    "(mu, sigma) = norm.fit(y_test)\n",
    "print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n",
    "\n",
    "# Now plot the distribution\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SalePrice distribution')\n",
    "\n",
    "# Get also the QQ-plot\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(y_test, plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction models for embedding + raw data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define MAPE metric, this will be used in addition to MAE and RMSE to evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(Y_actual,Y_Predicted):\n",
    "    mape = np.mean(np.abs((Y_actual - Y_Predicted)/Y_actual))*100\n",
    "    return mape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Gridsearch preformed for linear regression due to being irrelevant. Ridge, Lasso and ElasticNet models have been tested but performed worse compared to linear regression, thus the code was removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = linreg.predict(X_test)\n",
    "#Test set results\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "rmselog = mean_squared_error(np.expm1(y_test), np.expm1(y_pred), squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "maelog = mean_absolute_error(np.expm1(y_test), np.expm1(y_pred))\n",
    "mape = MAPE(y_test,y_pred)\n",
    "mapelog = MAPE(np.expm1(y_test), np.expm1(y_pred))\n",
    "#Training set results\n",
    "y_pred_tr = linreg.predict(X_train)\n",
    "rmse_tr = mean_squared_error(y_train, y_pred_tr, squared=False)\n",
    "mae_tr = mean_absolute_error(y_train, y_pred_tr)\n",
    "mape_tr = MAPE(y_train, y_pred_tr)\n",
    "print('Results of test set')\n",
    "print('R-squared|', linreg.score(X_test, y_test))\n",
    "print('RMSE_test|', round(rmse,4))\n",
    "print('MAE_test |', round(mae,4))\n",
    "print('MAPE_test|', round(mape,2), '%')\n",
    "print('*'*100)\n",
    "print('Results of training set')\n",
    "print('R-squared|', linreg.score(X_train, y_train))\n",
    "print('RMSE_train|', round(rmse_tr,4))\n",
    "print('MAE_train |', round(mae_tr,4))\n",
    "print('MAPE_train|', round(mape_tr,2), '%')\n",
    "print('*'*100)\n",
    "print('RMSE_testLOG|', round(rmselog,4))\n",
    "print('MAE_testLOG|', round(maelog,4))\n",
    "print('MAPE_testLOG|', round(mapelog,2), '%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost regressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gridsearch for XGB Regressor. Not all tested parameters being present due to not being able to run the code in one go. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "XGBR = XGBRegressor(objective = 'reg:squarederror')\n",
    "grid_param = {'n_estimators': [750,1000],\n",
    "              'max_depth': [7,9],\n",
    "              'learning_rate' : [0.02,0.03]\n",
    "              }\n",
    "grid_mse = GridSearchCV(estimator = XGBR, param_grid = grid_param, scoring = \"neg_mean_squared_error\", cv = 5, verbose = 1)\n",
    "grid_mse.fit(X_train, y_train,verbose=True)\n",
    "print(\"Best parameters found: \", grid_mse.best_params_)\n",
    "print(\"Lowest RMSE found: \", np.sqrt(np.abs(grid_mse.best_score_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBR = XGBRegressor(n_estimators = 750, objective = 'reg:squarederror', max_depth = 7, learning_rate = 0.02)\n",
    "XGBR.fit(X_train, y_train,verbose=True)\n",
    "y_pred = XGBR.predict(X_test)\n",
    "#Test set results\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "rmselog = mean_squared_error(np.expm1(y_test), np.expm1(y_pred), squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "maelog = mean_absolute_error(np.expm1(y_test), np.expm1(y_pred))\n",
    "mape = MAPE(y_test,y_pred)\n",
    "mapelog = MAPE(np.expm1(y_test), np.expm1(y_pred))\n",
    "#Training set results\n",
    "y_pred_tr = XGBR.predict(X_train)\n",
    "rmse_tr = mean_squared_error(y_train, y_pred_tr, squared=False)\n",
    "mae_tr = mean_absolute_error(y_train, y_pred_tr)\n",
    "mape_tr = MAPE(y_train, y_pred_tr)\n",
    "print('Results of test set')\n",
    "print('R-squared|', XGBR.score(X_test, y_test))\n",
    "print('RMSE_test|', round(rmse,4))\n",
    "print('MAE_test |', round(mae,4))\n",
    "print('MAPE_test|', round(mape,2), '%')\n",
    "print('*'*100)\n",
    "print('Results of training set')\n",
    "print('R-squared|', XGBR.score(X_train, y_train))\n",
    "print('RMSE_train|', round(rmse_tr,4))\n",
    "print('MAE_train |', round(mae_tr,4))\n",
    "print('MAPE_train|', round(mape_tr,2), '%')\n",
    "print('*'*100)\n",
    "print('RMSE_testLOG|', round(rmselog,4))\n",
    "print('MAE_testLOG|', round(maelog,4))\n",
    "print('MAPE_testLOG|', round(mapelog,2), '%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest regressor\n",
    "\n",
    "The random forest model takes the longest to run"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gridsearch for Random Forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "grid_param = {'n_estimators': [500,800],\n",
    "              'max_depth': [11,13,15],\n",
    "              'min_samples_split': [2,5],\n",
    "              }\n",
    "grid_mse = GridSearchCV(estimator = rf, param_grid = grid_param, scoring = \"neg_mean_squared_error\", cv = 5, verbose = 1)\n",
    "grid_mse.fit(X_train, y_train)\n",
    "print(\"Best parameters found: \", grid_mse.best_params_)\n",
    "print(\"Lowest RMSE found: \", np.sqrt(np.abs(grid_mse.best_score_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=800, max_depth=15, min_samples_split=5)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "#Test set results\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "rmselog = mean_squared_error(np.expm1(y_test), np.expm1(y_pred), squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "maelog = mean_absolute_error(np.expm1(y_test), np.expm1(y_pred))\n",
    "mape = MAPE(y_test,y_pred)\n",
    "mapelog = MAPE(np.expm1(y_test), np.expm1(y_pred))\n",
    "#Training set results\n",
    "y_pred_tr = rf.predict(X_train)\n",
    "rmse_tr = mean_squared_error(y_train, y_pred_tr, squared=False)\n",
    "mae_tr = mean_absolute_error(y_train, y_pred_tr)\n",
    "mape_tr = MAPE(y_train, y_pred_tr)\n",
    "print('Results of test set')\n",
    "print('R-squared|', rf.score(X_test, y_test))\n",
    "print('RMSE_test|', round(rmse,4))\n",
    "print('MAE_test |', round(mae,4))\n",
    "print('MAPE_test|', round(mape,2), '%')\n",
    "print('*'*100)\n",
    "print('Results of training set')\n",
    "print('R-squared|',rf.score(X_train, y_train))\n",
    "print('RMSE_train|', round(rmse_tr,4))\n",
    "print('MAE_train |', round(mae_tr,4))\n",
    "print('MAPE_train|', round(mape_tr,2), '%')\n",
    "print('*'*100)\n",
    "print('RMSE_testLOG|', round(rmselog,4))\n",
    "print('MAE_testLOG|', round(maelog,4))\n",
    "print('MAPE_testLOG|', round(mapelog,2), '%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling for RAW-only \n",
    "\n",
    "Feature engineering is not included with regards to geospatial information like amount of houses in certain proximity due to time limitations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data and drop variables that skew the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = pd.read_csv(\"BaseKCFinal.csv\")\n",
    "base_df = base_df.drop([\"id\"], axis=1)\n",
    "base_df = base_df.drop([\"index\"], axis=1)\n",
    "base_df = base_df.drop(base_df.columns[0],axis = 1)\n",
    "y = base_df[\"price\"]\n",
    "X = base_df.drop([\"price\"], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run following code only if influence of latitude and longitude on results has to be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Raw set without lat and lon\n",
    "df_no_lat =  base_df.drop(['lat','long'], axis = 1)\n",
    "base_df = df_no_lat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=420)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming house prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.log1p(y_train)\n",
    "y_test = np.log1p(y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_test)\n",
    "#Test set results\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "rmselog = mean_squared_error(np.expm1(y_test), np.expm1(y_pred), squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "maelog = mean_absolute_error(np.expm1(y_test), np.expm1(y_pred))\n",
    "mape = MAPE(y_test,y_pred)\n",
    "mapelog = MAPE(np.expm1(y_test), np.expm1(y_pred))\n",
    "#Training set results\n",
    "y_pred_tr = linreg.predict(X_train)\n",
    "rmse_tr = mean_squared_error(y_train, y_pred_tr, squared=False)\n",
    "mae_tr = mean_absolute_error(y_train, y_pred_tr)\n",
    "mape_tr = MAPE(y_train, y_pred_tr)\n",
    "print('Results of test set')\n",
    "print('R-squared|', linreg.score(X_test, y_test))\n",
    "print('RMSE_test|', round(rmse,4))\n",
    "print('MAE_test |', round(mae,4))\n",
    "print('MAPE_test|', round(mape,2), '%')\n",
    "print('*'*100)\n",
    "print('Results of training set')\n",
    "print('R-squared|', linreg.score(X_train, y_train))\n",
    "print('RMSE_train|', round(rmse_tr,4))\n",
    "print('MAE_train |', round(mae_tr,4))\n",
    "print('MAPE_train|', round(mape_tr,2), '%')\n",
    "print('*'*100)\n",
    "print('RMSE_testLOG|', round(rmselog,4))\n",
    "print('MAE_testLOG|', round(maelog,4))\n",
    "print('MAPE_testLOG|', round(mapelog,2), '%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost regressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gridsearch for RAW data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBR = XGBRegressor(objective = 'reg:squarederror')\n",
    "grid_param = {'n_estimators': [1000,1500],\n",
    "              'max_depth': [5,7],\n",
    "              'learning_rate' : [0.02,0.025]\n",
    "              }\n",
    "grid_mse = GridSearchCV(estimator = XGBR, param_grid = grid_param, scoring = \"neg_mean_squared_error\", cv = 5, verbose = 1)\n",
    "grid_mse.fit(X_train, y_train,verbose=True)\n",
    "print(\"Best parameters found: \", grid_mse.best_params_)\n",
    "print(\"Lowest RMSE found: \", np.sqrt(np.abs(grid_mse.best_score_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBR = XGBRegressor(n_estimators = 1000, objective = 'reg:squarederror', max_depth = 7, learning_rate = 0.025)\n",
    "XGBR.fit(X_train, y_train)\n",
    "y_pred = XGBR.predict(X_test)\n",
    "#Test set results\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "rmselog = mean_squared_error(np.expm1(y_test), np.expm1(y_pred), squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "maelog = mean_absolute_error(np.expm1(y_test), np.expm1(y_pred))\n",
    "mape = MAPE(y_test,y_pred)\n",
    "mapelog = MAPE(np.expm1(y_test), np.expm1(y_pred))\n",
    "#Training set results\n",
    "y_pred_tr = XGBR.predict(X_train)\n",
    "rmse_tr = mean_squared_error(y_train, y_pred_tr, squared=False)\n",
    "mae_tr = mean_absolute_error(y_train, y_pred_tr)\n",
    "mape_tr = MAPE(y_train, y_pred_tr)\n",
    "print('Results of test set')\n",
    "print('R-squared|', XGBR.score(X_test, y_test))\n",
    "print('RMSE_test|', round(rmse,4))\n",
    "print('MAE_test |', round(mae,4))\n",
    "print('MAPE_test|', round(mape,2), '%')\n",
    "print('*'*100)\n",
    "print('Results of training set')\n",
    "print('R-squared|', XGBR.score(X_train, y_train))\n",
    "print('RMSE_train|', round(rmse_tr,4))\n",
    "print('MAE_train |', round(mae_tr,4))\n",
    "print('MAPE_train|', round(mape_tr,2), '%')\n",
    "print('*'*100)\n",
    "print('RMSE_testLOG|', round(rmselog,4))\n",
    "print('MAE_testLOG|', round(maelog,4))\n",
    "print('MAPE_testLOG|', round(mapelog,2), '%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest regressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gridsearch for RAW data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "grid_param = {'n_estimators': [500,750],\n",
    "              'max_depth': [11],\n",
    "              'min_samples_split': [2,5],\n",
    "              }\n",
    "grid_mse = GridSearchCV(estimator = rf, param_grid = grid_param, scoring = \"neg_mean_squared_error\", cv = 5, verbose = 1)\n",
    "grid_mse.fit(X_train, y_train)\n",
    "print(\"Best parameters found: \", grid_mse.best_params_)\n",
    "print(\"Lowest RMSE found: \", np.sqrt(np.abs(grid_mse.best_score_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=500, max_depth=11,min_samples_split=2)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "#Test set results\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "rmselog = mean_squared_error(np.expm1(y_test), np.expm1(y_pred), squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "maelog = mean_absolute_error(np.expm1(y_test), np.expm1(y_pred))\n",
    "mape = MAPE(y_test,y_pred)\n",
    "mapelog = MAPE(np.expm1(y_test), np.expm1(y_pred))\n",
    "#Training set results\n",
    "y_pred_tr = rf.predict(X_train)\n",
    "rmse_tr = mean_squared_error(y_train, y_pred_tr, squared=False)\n",
    "mae_tr = mean_absolute_error(y_train, y_pred_tr)\n",
    "mape_tr = MAPE(y_train, y_pred_tr)\n",
    "print('Results of test set')\n",
    "print('R-squared|', rf.score(X_test, y_test))\n",
    "print('RMSE_test|', round(rmse,4))\n",
    "print('MAE_test |', round(mae,4))\n",
    "print('MAPE_test|', round(mape,2), '%')\n",
    "print('*'*100)\n",
    "print('Results of training set')\n",
    "print('R-squared|',rf.score(X_train, y_train))\n",
    "print('RMSE_train|', round(rmse_tr,4))\n",
    "print('MAE_train |', round(mae_tr,4))\n",
    "print('MAPE_train|', round(mape_tr,2), '%')\n",
    "print('*'*100)\n",
    "print('RMSE_testLOG|', round(rmselog,4))\n",
    "print('MAE_testLOG|', round(maelog,4))\n",
    "print('MAPE_testLOG|', round(mapelog,2), '%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance testing using SHAP values\n",
    "Utilize the test set if you want to better understand the predictions of the models on unseen data, the train set if \n",
    "you want to investigate the behavior of the model on specific training instances.\n",
    "\n",
    "1) XGBRegressor\n",
    "2) RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('XGB_Final', 'wb') as file:\n",
    "#         pickle.dump(XGBR, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially the shapley values must be computed of the various features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "def construct_shap_values(model):\n",
    "    explainer = shap.Explainer(model)\n",
    "    instance_index = 0\n",
    "    feature_names = X_test_concatenated.columns\n",
    "    shap_values = explainer(X_test_concatenated)\n",
    "    shap_values_df = pd.DataFrame(shap_values.values[0], index=feature_names, columns=[\"Shapley Values\"])\n",
    "    pd.set_option(\"display.max_rows\", None)\n",
    "    print(shap_values_df)\n",
    "    return shap_values_df, shap_values\n",
    "shap_values_df, shap_values = construct_shap_values(XGBR)\n",
    " # Onderstaande output moet in text editor geopend worden, anders ziet ge de volledige output niet. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The beeswarm plot visualizes the SHAP values per instance, which gives an insight on how the features are contributing to the model's predictions.\n",
    "Each dot in the plot bellow represents an instance of the test dataset, its position on the x-axis indicates the SHAP value for that instance and feature. A positive SHAP value means that the feature increases the prediction value relative to the average prediction of the model, negative SHAP value decreases the prediction value.\n",
    "\n",
    "The more spread out the dots are the more varied the impact of the feature is on the predictions. More dots clustered around the positive side means that a feature generally increases the prediction value, vice versa for the negative side. \n",
    "\n",
    "The color scheme on the side indicates the relationship between the feature values and their impact on the prediction of the model. In other words, it indicates the significance of the feature in influencing the outcome of the prediction model. \n",
    "\n",
    "E.g. High feature values with consistently high SHAP values, means that higher values of that feature lead to an increase in prediction. \n",
    "E.g. King county data: \"lat\" has more often a high feature importance, which implies that the variable has a significant impact on determining the prediction of the house price. It however also has a wide distribution, this indicates that the variable may be nonlinear or depend on other features in the model, such as \"lon\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_beeswarm(subset_shap_values):\n",
    "    total_features = X_test_concatenated.shape[1]\n",
    "    shap.plots.beeswarm(subset_shap_values, max_display=15)\n",
    "\n",
    "instance_indices = X_test_concatenated.index.to_numpy()\n",
    "subset_shap_values = shap_values[instance_indices]\n",
    "#subset_shap_values = subset_shap_values[:,:10]\n",
    "visualize_beeswarm(subset_shap_values)\n",
    "subset_shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test, feature_names=X_test_concatenated.columns, plot_type='violin', show=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=0.3)\n",
    "plt.xlabel(\"SHAP Value\")\n",
    "plt.ylabel(\"Feature\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bar chart indicates the average impact of the various features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below does the same but for the random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_df_rf, shap_values_rf = construct_shap_values(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_beeswarm(shap_values_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values_df_rf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
